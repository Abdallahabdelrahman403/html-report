<html>
<head>
<style>
a:link, a:visited {
  background-color: black;
  color: white;
  padding: 15px 25px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
}

a:hover, a:active {
  background-color:SlateBlue;
}
</style>
</head>
<body>

<center><h2>Artificial intelligence</h2><center>
<p></p>
<a href="Definition of artificial intelligence.html">Definition of artificial intelligence</a>
<a href="Applications of Artificial Intelligence.html">Applications of Artificial Intelligence</a>
<a href="The risk of artificial intelligence.html">The risk of artificial intelligence</a>
<a href="Uses of Artificial Intelligence.html">Uses of Artificial Intelligence</a>
<a href="future of artificial intelligence.html">future of artificial intelligence</a>
<h2>The risk of artificial intelligence<h2>
<p style="font-size:19px;">Most researchers agree that a superintelligent AI is unlikely to exhibit human emotions such as love 
or hate, and there is no reason to expect that AI will intentionally become benevolent or malevolent. 
Instead, experts will most likely think of two 
scenarios when considering how AI could become a risk:
<br>
1-To do something devastating, the AI is programmed: 
autonomous weapons are artificial intelligence systems programmed for killing. 
Those guns could easily cause mass casualties 
in the hands of the wrong individual. 
In addition, an AI arms race might inadvertently lead to 
an AI war, which would also result in mass casualties. 
These weapons would be designed to be extremely difficult to simply "turn off" to avoid 
being thwarted by the enemy, so humans could plausibly lose control of such a situation. 
This risk is present even with narrow AI, but 
increases with increasing levels of AI intelligence and autonomy
<br>
2- The AI is programmed to do something beneficial, but it develops a destructive method for achieving its objective: this 
can happen whenever we fail to fully align the AI 's objectives with ours, which is strikingly difficult to achieve. 
If you ask an obedient smart car to take you to the airport as quickly as possible, it might get 
you there chased by helicopters and coated in blood, not doing what you wanted but simply doing what you asked for. 
If an ambitious geoengineering project is charged with a superintelligent device, it could wreak havoc with our 
environment as a side-effect, and see human efforts to stop it as a threat to be met.<p>

</body>
</html>


